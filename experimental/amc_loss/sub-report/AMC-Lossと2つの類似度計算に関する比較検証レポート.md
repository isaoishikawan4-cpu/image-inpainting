# Quick精度検証レポート

## サマリー
本検証では、DINOv2ベースの髭カウントモデルにおいて、Angular Margin Contrastive Loss（AMC-Loss）の2つの変種を比較検証した。推論時の類似度計算方法（コサイン類似度 vs 角度距離の指数関数マッピング）の違いが検出精度に与える影響を調査した。

| モデル | 損失関数 | 推論時の類似度計算 | パラメータ1 (Th=70) | パラメータ2 (Th=10) |
|--------|----------|-------------------|---------------------|---------------------|
| モデルβ-1 | AMC-Loss | コサイン類似度 | 743本 | 689本 |
| モデルβ-2 | AMC-Loss | 角度距離→指数関数 | 21本 | 412本 |

**結論**: モデルβ-2（角度距離の指数関数マッピング）は、推論パラメータへの感度が極めて高く、閾値調整により検出数が劇的に変化する。一方、モデルβ-1（コサイン類似度）は安定した検出を行うが過検出傾向がある。**髭カウント精度の観点では、モデルβ-2のパラメータ2（Threshold=10）が最も現実的な検出数（412本）を示し、推奨される**。

## 1. 背景・目的
前回の検証（Supervised Contrastive Loss vs AMC-Loss）において、AMC-Lossが高感度だが過検出傾向を示すことが判明した。本検証では、AMC-Lossの理論的基盤である「角度空間での距離最適化」を推論時にも活用することで、検出精度が向上するかを検証する。

具体的には、推論時の類似度計算方法を変更し、以下の2つのアプローチを比較する：
- **モデルβ-1**: コサイン類似度をそのまま使用（従来手法）
- **モデルβ-2**: 角度距離を指数関数でマッピング（AMC-Lossの理論的整合性を保持）

## 2. 検証アプローチ

### 2.1 検証環境・設定

**基本アーキテクチャ（共通）**
- エンコーダ: DINOv2 (dinov2_vitg14) - 凍結
- 分類器: 5層MLP（hidden_dim=256, dropout=0.3）
- Projection Head: 2層MLP（projection_dim=128）
- 損失関数: AMC-Loss（margin=0.5, scale=64.0）

**使用データ**
- 35251205_20250803.jpg
- 35251206_20250803.jpg
- 35251222_20250806.jpg

**推論パラメータ1（高閾値設定）**
- Threshold: 70%
- Min Area: 5 pixels
- Max Area: 100 pixels
- Circularity: 30%

**推論パラメータ2（低閾値設定）**
- Threshold: 10%
- Min Area: 5 pixels
- Max Area: 30 pixels
- Circularity: 30%

**共通学習パラメータ**
- エポック数: 50
- バッチサイズ: 32
- 学習率: 0.001
- Contrastive Loss重み: 2.0

### 2.2 比較対象

**β-1. コサイン類似度ベース vs β-2. 角度距離の指数関数マッピング の理論的差異**

| 特性 | β-1. コサイン類似度 | β-2. 角度距離→指数関数 |
|------|---------------------|------------------------|
| 計算式 | `sim = cos(θ)` | `sim = exp(-k · θ / margin)` |
| 値域 | [-1, 1] | [0, 1]（θ=0で1、θ増加で急減） |
| 特性 | 線形的な類似度減衰 | 指数関数的な類似度減衰 |
| AMC-Loss理論との整合性 | 学習時と推論時で計算方法が異なる | 学習時と推論時で角度空間を統一 |

**β-1. コサイン類似度ベース（[dinov2_inference_viewer.py:503](dinov2_inference_viewer.py#L503)）**
```python
# 推論時
similarity_map = torch.matmul(embeddings_gpu, avg_embedding_gpu)  # コサイン類似度
```
- 従来の標準的な手法
- 類似度が線形的に減衰（cos(θ) は θ=0°で1、θ=90°で0）
- 学習時はAMC-Lossで角度距離を最適化するが、推論時はコサイン類似度を使用（不整合）

**β-2. 角度距離の指数関数マッピング（[dinov2_inference_viewer_v3.py:559-586](dinov2_inference_viewer_v3.py#L559-L586)）**
```python
# 推論時
cosine_sim = torch.matmul(embeddings_gpu, avg_embedding_gpu)
theta = torch.acos(torch.clamp(cosine_sim, -1.0 + eps, 1.0 - eps))  # 角度変換
similarity_map = torch.exp(-4.0 * (theta / margin))  # 指数関数マッピング
```
- AMC-Lossの理論的基盤である「角度空間での距離」を推論時にも使用
- 指数関数により、角度が離れると類似度が急激に減衰
- 係数4.0は可視化時の赤色領域の広がりを調整する感度パラメータ
- margin（0.5 rad ≈ 28.6°）を基準にスコアリング

## 3. 検証結果

### 3.1 定量的評価

**推論パラメータ1（Threshold=70, Min Area=5, Max Area=100）での比較**

| モデル | 推論時の類似度計算 | 検出数 | 検出領域の特徴 |
|--------|-------------------|--------|----------------|
| モデルβ-1 | コサイン類似度 | 743本 | 広範囲（頬・鼻周辺含む） |
| モデルβ-2 | 角度距離→指数関数 | 21本 | 極めて限定的（顎の一部のみ） |

**推論パラメータ2（Threshold=10, Min Area=5, Max Area=30）での比較**

| モデル | 推論時の類似度計算 | 検出数 | 検出領域の特徴 |
|--------|-------------------|--------|----------------|
| モデルβ-1 | コサイン類似度 | 689本 | 広範囲、やや過検出 |
| モデルβ-2 | 角度距離→指数関数 | 412本 | 髭領域に集中、適度な検出 |

### 3.2 密度マップ

**モデルβ-1（コサイン類似度）の検出結果**

*推論パラメータ1（Threshold=70）*

![モデルβ-1 パラメータ1](outputs/counting_results_AMC-Loss1-1.png)

- 検出数: 743本
- 赤色の皮膚領域（類似度マスク）が広範囲
- 髭以外の領域（頬、鼻周辺）にも多数の緑色マーカー（検出）

*推論パラメータ2（Threshold=10）*

![モデルβ-1 パラメータ2](outputs/counting_results_AMC-Loss1-2.png)

- 検出数: 689本
- 閾値を下げても検出数があまり減少しない（安定性）
- 依然として広範囲に検出

**モデルβ-2（角度距離の指数関数マッピング）の検出結果**

*推論パラメータ1（Threshold=70）*

![モデルβ-2 パラメータ1](outputs/counting_results_AMC-Loss_v3-1.png)

- 検出数: 21本
- 赤色領域が非常に限定的（鼻下、顎の一部のみ）
- 極端に保守的な検出

*推論パラメータ2（Threshold=10）*

![モデルβ-2 パラメータ2](outputs/counting_results_AMC-Loss_v3-2.png)

- 検出数: 412本
- 赤色領域が口周り・顎に適度に広がる
- 髭領域に集中した検出

## 4. 考察

### 4.1 特徴分析

**検出数の劇的な差異が生じた原因**

1. **類似度の減衰特性の違い**
   - **コサイン類似度**: cos(θ) は θ が小さい範囲で緩やかに減衰（θ=30°で cos≈0.866）
   - **指数関数マッピング**: exp(-4.0 · θ / 0.5) は θ が増加すると急激に減衰（θ=0.25 rad ≈ 14.3°で約0.135）
   - 指数関数の係数4.0により、わずかな角度差で類似度が大きく変化

2. **閾値への感度**
   - **モデルβ-1**: Threshold 70→10 で 743→689本（-7.3%）と変化が小さい
   - **モデルβ-2**: Threshold 70→10 で 21→412本（+1862%）と劇的に増加
   - 指数関数的減衰により、低い類似度範囲での差が大きく、閾値の影響が顕著

3. **学習と推論の整合性**
   - **モデルβ-1**: 学習時は角度距離（AMC-Loss）、推論時はコサイン類似度（不整合）
   - **モデルβ-2**: 学習時も推論時も角度ベース（整合性あり）
   - モデルβ-2は理論的に一貫しているが、指数関数の急峻さが極端な挙動を生む

**各手法が得意/苦手とするデータの傾向**

| 手法 | 得意なケース | 苦手なケース |
|----------|--------------|--------------|
| コサイン類似度 | 広範囲の特徴をカバーしたい場合 | 過検出を避けたい場合 |
| 角度距離→指数関数 | 高精度な髭領域の特定 | パラメータ調整が難しい（感度が高すぎる） |

### 4.2 エラー分析

**モデルβ-1（コサイン類似度）の誤検知傾向**
- **False Negative（検出漏れ）**: 少ない（高感度）
- **False Positive（誤検出）**: 多い（頬、鼻周辺のテクスチャを髭と誤認）
- **推論パラメータへの感度**: 低い（安定しているが改善余地が少ない）

**モデルβ-2（角度距離の指数関数マッピング）の誤検知傾向**
- **False Negative（検出漏れ）**: Threshold=70 では極めて多い（21本は過小検出）
- **False Positive（誤検出）**: Threshold=10 では適度（412本は現実的）
- **推論パラメータへの感度**: 極めて高い（適切な調整で最適化可能だが、運用が難しい）

## 5. 今後の課題

**本検証の限界事項**
1. Ground Truth（正解データ）がないため、絶対的な精度評価ができていない
2. 指数関数の係数（4.0）が経験的に設定されており、理論的根拠が不明
3. 検証画像が限定的で、汎化性能の評価が不十分

**髭カウント精度向上のための追加検証・改善案**

1. **モデルβ-2の改善**
   - 指数関数の係数を調整可能にする（4.0 → 1.0〜10.0 の範囲で最適化）
   - ソフトな指数関数（例: `exp(-k · θ²)` や `1 / (1 + k · θ²)`）の検討
   - 類似度マップの正規化手法の改善

2. **ハイブリッドアプローチ**
   - コサイン類似度と角度距離の加重平均
   - 閾値の適応的調整（画像ごとに自動最適化）

3. **AMC-Lossのハイパーパラメータ再調整**
   - marginを0.3〜0.7の範囲で探索
   - scaleを32〜128の範囲で探索
   - 学習時の挙動が推論時の性能に与える影響を詳細分析

4. **後処理の改善**
   - SimpleBlobDetectorのパラメータを画像特性に応じて適応的に調整
   - Heatmapの正規化方法の見直し（min-max正規化 vs パーセンタイル正規化）

5. **Ground Truthの作成と定量評価**
   - 手動アノテーションによる正解データの作成
   - Precision, Recall, F1-scoreによる定量評価

## 6. 結論

**精度面からの判断**
- **モデルβ-1（コサイン類似度）**: 安定した検出だが過検出傾向が強い（689〜743本）。閾値調整による改善余地が少ない。
- **モデルβ-2（角度距離の指数関数マッピング）**: 推論パラメータへの感度が極めて高く、適切な調整により現実的な検出数（412本）を達成。ただし、運用上はパラメータ調整の難易度が高い。

**推奨**
**モデルβ-2（角度距離の指数関数マッピング）を推論パラメータ2（Threshold=10, Min Area=5, Max Area=30）で使用することを推奨する**。理由は以下の通り：

1. **理論的整合性**: 学習時（AMC-Loss）と推論時（角度距離）で角度空間を統一し、理論的に一貫している
2. **適度な検出数**: 412本という検出数は、画像の髭密度から判断して最も現実的
3. **髭領域への集中**: 赤色の類似度マスクが口周り・顎に集中し、誤検出が少ない

**ただし、以下の制約事項に注意**：
- 指数関数の急峻な減衰により、推論パラメータ（特にThreshold）への感度が極めて高い
- 画像ごとに最適なThresholdが異なる可能性があり、運用時には調整が必要
- Ground Truthがないため、412本が真の正解に近いかは未検証

**今後の方向性**：
1. Ground Truthを作成し、Precision/Recallで定量評価
2. 指数関数の係数を調整可能なパラメータとして最適化
3. 複数の画像で検証し、Thresholdの推奨値を統計的に決定

## 参考文献・付録

**参考文献**
1. Choi, Y., et al. (2020). "AMC-Loss: Angular Margin Contrastive Loss for Improved Explainability in Image Classification." *CVPRW 2020*. https://openaccess.thecvf.com/content_CVPRW_2020/papers/w50/Choi_AMC-Loss_Angular_Margin_Contrastive_Loss_for_Improved_Explainability_in_Image_CVPRW_2020_paper.pdf
2. Oquab, M., et al. (2023). "DINOv2: Learning Robust Visual Features without Supervision." *arXiv:2304.07193*

**付録: 関連ファイル**
- 学習スクリプト（β-1）: [dinov2_train_amc.py](dinov2_train_amc.py)
- 学習スクリプト（β-2）: [dinov2_train_amc_v3.py](dinov2_train_amc_v3.py)
- 推論スクリプト（β-1）: [dinov2_inference_viewer.py](dinov2_inference_viewer.py)
- 推論スクリプト（β-2）: [dinov2_inference_viewer_v3.py](dinov2_inference_viewer_v3.py)
- 学習済みモデル（β-1）: `classifier_AMCloss.pth`
- 学習済みモデル（β-2）: `classifier_AMCloss_v3.pth`（存在する場合）

**技術的詳細: 角度距離の指数関数マッピング**

推論時の類似度計算（[dinov2_inference_viewer_v3.py:559-586](dinov2_inference_viewer_v3.py#L559-L586)）:
```python
# 1. コサイン類似度を計算
cosine_sim = torch.matmul(embeddings_gpu, avg_embedding_gpu)

# 2. 角度θ（0〜π）に変換
theta = torch.acos(torch.clamp(cosine_sim, -1.0 + eps, 1.0 - eps))

# 3. 指数関数でスコアリング
# margin=0.5 rad を基準に、角度が離れると急激にスコアを下げる
# 係数 4.0 は可視化時の赤色領域の広がりを調整する感度パラメータ
similarity_map = torch.exp(-4.0 * (theta / margin))
```

学習時のAMC-Loss（[dinov2_train_amc_v3.py:251-289](dinov2_train_amc_v3.py#L251-L289)）:
```python
# 1. コサイン類似度から角度距離に変換
cosine_sim = torch.matmul(embeddings, embeddings.T)
theta = torch.acos(torch.clamp(cosine_sim, -1.0 + eps, 1.0 - eps))

# 2. 正例: 角度を0に近づける（同一クラス内で密集）
loss_pos = (theta ** 2) * mask_pos

# 3. 負例: marginより近い場合にペナルティ（異なるクラス間で分離）
loss_neg = (torch.clamp(margin - theta, min=0.0) ** 2) * mask_neg

# 4. 全体にscaleをかけて損失の大きさを調整
loss = scale * ((loss_pos.sum() / num_pos) + (loss_neg.sum() / num_neg))
```

この実装により、学習時と推論時の両方で角度空間を使用し、理論的整合性を保持している。
